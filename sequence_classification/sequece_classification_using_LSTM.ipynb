{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4328e959-3028-4c03-bb7d-e71fe6635b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03d54b78-57da-41c3-a740-901d36f6c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1c26891b-f40f-4cfa-8d85-0bf4a497ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# torch \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch import optim \n",
    "\n",
    "# torchtexts\n",
    "# from torchtext.data.utils import get_tokenizer\n",
    "# from torchtext.datasets import AG_NEWS\n",
    "# from torchtext.vocab import build_vocab_from_iterator\n",
    "# import torchtext.transforms as T\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec391bd1-0ca2-4826-b85d-aa3f04ecdbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'very', 'with', 'some', 'more', \"we'll\", 'through', 'do', 'if', 'about', 'a', 'doesn', \"i'd\", 'there', 'itself', \"hadn't\", 'couldn', 'yourselves', 'shan', 'now', 'when', 'at', 're', 'them', 'to', 'ain', 'here', 'shouldn', 'because', 'an', 'by', 'are', 'just', \"should've\", \"needn't\", 'this', \"mustn't\", \"couldn't\", \"he'd\", 'their', \"she'll\", 'does', \"they're\", 'other', 'until', 'in', 'hadn', 'its', \"mightn't\", 'off', 'my', 'the', 'only', 'she', 'yours', \"you'd\", \"wasn't\", 'but', \"they'd\", 'who', 'should', \"shouldn't\", \"he'll\", 'over', \"doesn't\", \"hasn't\", \"i've\", \"i'll\", \"it's\", \"aren't\", 'can', 'and', 'of', 'isn', 'is', 'own', 'what', \"i'm\", 'hasn', 'themselves', 'mustn', 'during', \"we're\", 'being', 'while', 'so', \"you're\", 'yourself', 'down', 'on', 'him', 'any', 'how', 'few', 'be', 'our', \"they've\", 'his', 'same', 'theirs', 'these', 'out', 'than', 'which', 'ma', \"she's\", \"that'll\", 'most', 'or', 'after', \"isn't\", 'have', 'aren', 'were', 'each', 'having', 't', \"it'd\", 'did', 'don', 'he', 'against', 'both', 'himself', \"didn't\", \"weren't\", 'again', 'between', 'weren', 'me', 'mightn', 'once', 's', 'whom', 'into', 'below', \"haven't\", \"he's\", 'too', 'further', 'above', \"you've\", 'haven', 'nor', 'd', 'll', 'that', 'will', \"you'll\", 'y', 'those', \"they'll\", 'all', 'then', \"she'd\", 'such', 'ours', 'doing', 'for', 'your', 'myself', \"won't\", 'i', 'has', 'wouldn', 'o', 'her', 'won', 'why', 'where', 'been', \"shan't\", 'no', 'didn', 'had', \"wouldn't\", \"it'll\", 'up', 'you', 'as', 'they', 'from', 'herself', \"we've\", 'we', 'm', 'under', \"don't\", 'not', 'before', 've', \"we'd\", 'ourselves', 'hers', 'was', 'needn', 'am', 'wasn', 'it'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords') #Download the NLTK Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61886dc9-264b-4bdc-8dc6-4d260aa7bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "learning_rate = 1e-4  # Learning rate for the optimizer\n",
    "nepochs = 20  # Number of training epochs\n",
    "batch_size = 32  # Batch size for training\n",
    "\n",
    "max_len = 128  # Maximum length of input sequences\n",
    "data_set_root = \"./datasets\"  # Root directory of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bdd51e-39a1-4f56-bc1e-b5f033cb63bb",
   "metadata": {},
   "source": [
    "# Dataset, Tokenizers and Vocab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a76f3d69-cf60-47ed-814d-fe3599609749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['labeledBow.feat',\n",
       "  'neg',\n",
       "  'pos',\n",
       "  'unsup',\n",
       "  'unsupBow.feat',\n",
       "  'urls_neg.txt',\n",
       "  'urls_pos.txt',\n",
       "  'urls_unsup.txt'],\n",
       " ['0_9.txt', '10000_8.txt', '10001_10.txt', '10002_7.txt', '10003_8.txt'],\n",
       " 10121,\n",
       " 12500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_root_dir=  os.path.join(\"..\",\"data\",\"aclImdb\",\"train\")\n",
    "train_pos_dir_path= os.path.join(dataset_root_dir, \"pos\")\n",
    "train_neg_dir_path= os.path.join(dataset_root_dir, \"neg\")\n",
    "\n",
    "os.listdir(dataset_root_dir), os.listdir(train_pos_dir_path)[:5], len(os.listdir(train_pos_dir_path)), len(os.listdir(train_neg_dir_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487939e-0f1f-476d-ac66-9b9888c038ce",
   "metadata": {},
   "source": [
    "## Create the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e4175cb-4403-4b5d-99e3-739cbd0ed9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentence Length 124.03602846912162\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "dataset_root_dir=  os.path.join(\"..\",\"data\",\"aclImdb\",\"train\")\n",
    "train_pos_dir_path= os.path.join(dataset_root_dir, \"pos\")\n",
    "train_neg_dir_path= os.path.join(dataset_root_dir, \"neg\")\n",
    "\n",
    "path_to_pos_text:list = [os.path.join(train_pos_dir_path, x) for x in os.listdir(train_pos_dir_path)]\n",
    "path_to_neg_text:list = [os.path.join(train_neg_dir_path, x) for x in os.listdir(train_neg_dir_path)]\n",
    "\n",
    "complete_training_data_path :list=  path_to_pos_text + path_to_neg_text\n",
    "\n",
    "punctuations= string.punctuation\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "### Easy Text Analysis ###\n",
    "\n",
    "alltxt = []\n",
    "len_words = []\n",
    "\n",
    "for file in complete_training_data_path:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        text_data:list = f.readlines()\n",
    "        text_data:str = text_data[0].strip().lower()\n",
    "        text_data:str = \"\".join([x for x in text_data if x not in punctuations]) # remove punctuations\n",
    "        text_data:list = word_tokenize(text_data)\n",
    "        text_data= [x for x in text_data if (x not in stopwords) and (len(x) > 0)] #remove stopwords and blank text\n",
    "        alltxt += text_data\n",
    "        len_words.append(len(text_data)) \n",
    "        f.close()\n",
    "\n",
    "import numpy as np\n",
    "print(\"Average Sentence Length\", np.mean(len_words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "578c728d-6d8f-4f80-8164-36bd8d6a5fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(len_words, bins= 50 , kde=True, color=\"red\")\n",
    "plt.xlabel(\"len of sequence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795fcd9d-e65d-4504-8ef7-db29d1cb9feb",
   "metadata": {},
   "source": [
    "## Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8db3d080-5b8b-4134-8ca6-c553035930a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique voacbulary words count :  114390\n",
      "Filtered voacbulary words count :  904\n"
     ]
    }
   ],
   "source": [
    "#### GEt conunt and unique words ####\n",
    "unique_counts = dict(Counter(alltxt))\n",
    "\n",
    "words = sorted([key for (key,value) in unique_counts.items() if value > 500])  # select the words having frequncy > 500\n",
    "\n",
    "# add special tokens\n",
    "words.append(\"<UNK>\")\n",
    "words.append(\"<PAD>\")\n",
    "\n",
    "word2indx= {word:idx for idx, word in enumerate(words)}\n",
    "indx2word = {idx:word for idx, word in enumerate(words)}\n",
    "\n",
    "print(f\"Unique voacbulary words count : \", len(unique_counts))\n",
    "print(f\"Filtered voacbulary words count : \", len(word2indx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3682d2b4-e9a6-4534-bdb2-77bcdd5cd5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "# Metadata and structure\n",
    "vocab_data = {\n",
    "    \"version\": \"1.0\",\n",
    "    \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"vocabulary\": word2indx\n",
    "}\n",
    "\n",
    "vocab_filepath= \"Vocabulary.json\"\n",
    "with open(vocab_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(vocab_data, f, indent=4)\n",
    "    f.close()\n",
    "\n",
    "print(f\"Vocabulary saved to {vocab_filepath} file..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949d274e-5f8e-400b-bdb3-d1c3f0f88e93",
   "metadata": {},
   "source": [
    "## Load vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "029508c9-d418-40ed-9749-9e82fa287056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary loaded successfully! \n",
      "\n",
      "dict_keys(['version', 'created_at', 'vocabulary']) \n",
      "\n",
      "Metadata : \n",
      "\t 1.0 \n",
      "\t 2025-04-28 17:24:10\n"
     ]
    }
   ],
   "source": [
    "# load vocab_data\n",
    "vocab_filepath= \"Vocabulary.json\"\n",
    "\n",
    "def load_vocabulary(vocab_filepath):\n",
    "    if os.path.exists(vocab_filepath):\n",
    "        try:\n",
    "            with open(vocab_filepath, \"r\") as f:\n",
    "                v_ = json.load(f)\n",
    "                f.close()\n",
    "                print(\"Vocabulary loaded successfully! \\n\")\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    else:\n",
    "        print(f\"Provided path {vocab_filepath} does not exists\")\n",
    "    return v_ \n",
    "\n",
    "\n",
    "vocab_= load_vocabulary(vocab_filepath)\n",
    "print(vocab_.keys(), \"\\n\")\n",
    "print(f\"Metadata : \\n\\t {vocab_['version']} \\n\\t {vocab_['created_at']}\")\n",
    "vocabulary= vocab_['vocabulary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebd6d57-e23c-4a81-93c1-03b535d62553",
   "metadata": {},
   "source": [
    "# Build IMDB Dataset\n",
    "\n",
    "We want to follow the same preprocessing steps we did above to make sure its accurate. We will fill words that are not in our tokenizer with Unknown tokens. This will follow our"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c86f7aaa-63af-4cf6-a212-2972975d368b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset): \n",
    "    def __init__(self, path_to_data, word2idx, max_seq_len=200):\n",
    "        self.word2idx= word2idx\n",
    "        path_to_pos_fld = os.path.join(path_to_data, \"pos\")\n",
    "        path_to_neg_fld = os.path.join(path_to_data, \"neg\")\n",
    "        \n",
    "        path_to_pos_txt = [os.path.join(path_to_pos_fld, file) for file in os.listdir(path_to_pos_fld)]\n",
    "        path_to_neg_txt = [os.path.join(path_to_neg_fld, file) for file in os.listdir(path_to_neg_fld)]\n",
    "        \n",
    "        self.training_files = path_to_pos_txt + path_to_neg_txt\n",
    "        self.tokenizer = word2idx #tokenize the text (word to int)\n",
    "        self.max_len = max_seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.training_files) \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path_to_txt = self.training_files[idx]\n",
    "\n",
    "        #### prep text #### \n",
    "        with open(path_to_txt,\"r\", encoding=\"utf-8\") as f:\n",
    "             txt = f.readlines()[0].strip().lower()\n",
    "             f.close()\n",
    "        \n",
    "        txt:str = \"\".join([x for x in txt if x not in punctuations]) # remove punctuations\n",
    "        txt:list = word_tokenize(txt)\n",
    "        txt = [x for x in txt if (x not in stopwords) and (len(x) > 0)] #remove stopwords and blank text\n",
    "        \n",
    "        tokenized= [] \n",
    "        for word in txt:\n",
    "             if word in self.tokenizer.keys():\n",
    "                 tokenized.append(self.tokenizer[word])\n",
    "             else:\n",
    "                 tokenized.append(self.tokenizer['<UNK>'])\n",
    "        \n",
    "        sample = torch.tensor(tokenized)\n",
    "        if len(sample) > self.max_len:\n",
    "            diff = len(sample) - self.max_len\n",
    "            start_idx = np.random.randint(diff)\n",
    "            sample = sample[start_idx:start_idx+self.max_len]\n",
    "\n",
    "        ### GRAB CLASS LABEL ###\n",
    "        if \"neg\" in path_to_txt:\n",
    "            label = 0\n",
    "        else:\n",
    "            label = 1\n",
    "            \n",
    "        return sample, label        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7212fb37-fde8-4d8c-8864-007561726eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "imdbdataset = MyDataset(dataset_root_dir, vocabulary)\n",
    "### Check Dataset Works ###\n",
    "counter = 0\n",
    "for data, label in imdbdataset:\n",
    "    print(data.shape)\n",
    "    print(label)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d3586e04-825d-4be2-8a2a-c34d98e61c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write Custom Collator ###\n",
    "def data_collator(batch):\n",
    "    texts, labels = [], []\n",
    "    \n",
    "    for text, label in batch:\n",
    "        labels.append(label)\n",
    "        texts.append(text)\n",
    "        \n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    ### Pad the list of sequences and then convert to tensor like example above but with our padding token <PAD> ###\n",
    "    texts = nn.utils.rnn.pad_sequence(texts, batch_first=True, padding_value=word2idx[\"<PAD>\"])\n",
    "    return texts, labels   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "949847fa-f1ad-4429-b385-d2948efe6342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[902, 902, 902,  ..., 903, 903, 903],\n",
      "        [881, 902, 508,  ..., 903, 903, 903],\n",
      "        [572, 191, 902,  ..., 903, 903, 903],\n",
      "        ...,\n",
      "        [902, 134, 623,  ..., 903, 903, 903],\n",
      "        [902, 902, 902,  ..., 903, 903, 903],\n",
      "        [103, 172,  15,  ..., 903, 903, 903]])\n",
      "tensor([0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "#### Data Loader ####\n",
    "imdbloader = DataLoader(imdbdataset, \n",
    "                        batch_size=16, \n",
    "                        shuffle=True, \n",
    "                        collate_fn=data_collator)\n",
    "\n",
    "\n",
    "counter = 0\n",
    "for text, label in imdbloader:\n",
    "    print(text)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e3fdf-15ca-4bad-a4ea-a92a6641819a",
   "metadata": {},
   "source": [
    "Our Dataset has now been converted to a series of numbers, but we still have a small issue. These numbers don't really mean anything... We just randomly assigned some integer value to each of these words but that doesn't mean they can express the meaning of the word. Therefore we have to use something called an Embedding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13f03c-2b3f-4277-bce5-dee7c3cfd5b1",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "\n",
    "Embeddings are numerical representation of some concept. In our case specifically, we want to represent a specific word with a vector of lenght 256 (arbritrary value that I picked, you can use much larger embedding dimensions). Our goal during the training process is to have words that are similar in meaning to have vectors that are closer together in the high dimensional space. For example, we want words like, Bad, Horrible, and Terrible to be closer together but far apart from words like Good, Amazing, Incredible. To do this we can use something known as a PyTorch Embedding!\n",
    "\n",
    "The embedding we want will have a row for each unique word in our corpus (along with unknown and padding) and the width will be our embedding dimension. This will be a simple lookup table, where if we want the embedding that goes with the word labeled with the index 3, then we grab the 3rd row of the embedding table. Lets try this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5775fcd3-d2c1-4d3c-a856-82f1754a3c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Weights\n",
      "Parameter containing:\n",
      "tensor([[ 0.5464, -0.2611,  0.4911],\n",
      "        [ 1.5574,  1.9191,  1.1514],\n",
      "        [ 1.4311, -0.1380, -0.2176],\n",
      "        [ 0.4189,  0.4691, -0.4236],\n",
      "        [ 0.3551, -0.9436, -0.1065]], requires_grad=True)\n",
      "Embedding for Single Sentence\n",
      "tensor([[ 1.5574,  1.9191,  1.1514],\n",
      "        [ 0.4189,  0.4691, -0.4236]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([2, 3])\n",
      "Embedding for Batch Sentence\n",
      "Batch shape :  torch.Size([3, 2])\n",
      "tensor([[[ 1.5574,  1.9191,  1.1514],\n",
      "         [ 0.4189,  0.4691, -0.4236]],\n",
      "\n",
      "        [[ 1.5574,  1.9191,  1.1514],\n",
      "         [ 0.4189,  0.4691, -0.4236]],\n",
      "\n",
      "        [[ 1.5574,  1.9191,  1.1514],\n",
      "         [ 0.4189,  0.4691, -0.4236]]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "emb = nn.Embedding(5,3)\n",
    "\n",
    "print(\"Embedding Weights\")\n",
    "print(emb.weight)\n",
    "\n",
    "print(\"Embedding for Single Sentence\")\n",
    "sentence = torch.tensor([1, 3]) # Sentence words as a list of numbers\n",
    "print(emb(sentence))\n",
    "print(emb(sentence).shape)\n",
    "\n",
    "print(\"Embedding for Batch Sentence\")\n",
    "batch_sentences = torch.tensor([[1,3], \n",
    "                                [1,3], \n",
    "                                [1,3]])\n",
    "print(\"Batch shape : \" , batch_sentences.shape)\n",
    "print(emb(batch_sentences))\n",
    "print(emb(batch_sentences).shape) # batch_size, seq_len, emb_dims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "48ed8c0e-4e18-4440-ade9-4320ba3699b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4311, -0.1380, -0.2176],\n",
      "        [ 1.4311, -0.1380, -0.2176],\n",
      "        [ 1.4311, -0.1380, -0.2176],\n",
      "        [ 0.4189,  0.4691, -0.4236]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "sentence = torch.tensor([2, 2, 2, 3]) # Sentence words as a list of numbers\n",
    "print(emb(sentence))\n",
    "print(emb(sentence).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df95ef63-78ec-466e-889d-e188f7838385",
   "metadata": {},
   "source": [
    "**Explore the LSTM Module**\n",
    "\n",
    "```python\n",
    "nn.LSTM(input_size,  # Expected number of features per input (in our case it will be the embedding depth)\n",
    "        hidden_size, # Number of features in Hidden State\n",
    "        num_layers,  # Number of LSTM Cells we want to stack\n",
    "        batch_first, # Will our tensor have batch dimension or sequence dimension first\n",
    ")\n",
    "```\n",
    "\n",
    "**Inputs to the LSTM**\n",
    "\n",
    "    H0: Num Layers x batch_size x Hidden Size -> Initialized as 0 if no information given\n",
    "    C0: Num Layers x batch_size x Hidden Size -> Initialized as 0 if no information give\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "99188880-a67e-42e9-a852-becf520f9988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: torch.Size([5, 15, 20])\n",
      "Final H: torch.Size([2, 5, 20])\n",
      "Final c: torch.Size([2, 5, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 5        # How Many Samples\n",
    "sequence_length = 15  # Sequence Length Per Sample\n",
    "input_size = 10       # Dimension of vector for each timestep in sequence per sample      \n",
    "hidden_size = 20      # Dimension expansion from Input size Inside the LSTM cell\n",
    "num_layers = 2        # Number of LSTM Cells\n",
    "\n",
    "lstm = nn.LSTM(input_size=input_size,\n",
    "               hidden_size=hidden_size, \n",
    "               num_layers=num_layers,\n",
    "               batch_first=True)\n",
    "\n",
    "\n",
    "\n",
    "rand = torch.rand(batch_size, sequence_length, input_size) # Batch x sequence length x input_size\n",
    "h0 = torch.zeros(num_layers, batch_size, hidden_size)      # Num Layers x Batch Size x Hidden State\n",
    "c0 = torch.zeros(num_layers, batch_size, hidden_size)      # Num Layers x Batch Size x Hidden State\n",
    "\n",
    "output, (hn, cn) = lstm(rand, (h0, c0))\n",
    "\n",
    "print(\"Output:\", output.shape) # Returns Batch Size x Sequence Length x Hidden Size -> Hidden state for each timestep\n",
    "print(\"Final H:\", hn.shape)    # Returns Num Layers x Batch Size x Hidden Size -> Last Hidden state for every layer\n",
    "print(\"Final c:\", cn.shape)    # Returns Num Layers x Batch Size x Hidden Size -> Last Hidden state for every layer\n",
    "\n",
    "hn[-1][0] == output[0][-1] # Check if the Last layer, first sample of Hn has same hidden size as first sample, last timestep of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e31f62f3-18fe-4439-b850-1ae1b46a7a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 15, 20])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7d6e122a-a0a9-4050-a3ae-92fee1a8f9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0424,  0.0389,  0.0940,  0.0288, -0.0779,  0.1395, -0.1450,  0.1436,\n",
       "         -0.0711,  0.0852,  0.0281, -0.0388,  0.0989, -0.0089, -0.1089, -0.0018,\n",
       "          0.0923,  0.1267,  0.0961,  0.0648], grad_fn=<SelectBackward0>),\n",
       " torch.Size([20]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][-1], output[0][-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3b31ad-e33d-414c-a624-535fe8fa2297",
   "metadata": {},
   "source": [
    "# Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "eb7170b3-00fd-4bc6-8e99-26d98e4d5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dims, no_layers, no_hidden, no_classes, device):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        # super().__init__()\n",
    "        self.vocab_size:int = vocab_size \n",
    "        self.embedding_dims:int = embedding_dims\n",
    "        self.no_layers:int = no_layers \n",
    "        self.no_hidden:int = no_hidden \n",
    "        self.classes:int = no_classes \n",
    "        self.device = device \n",
    "\n",
    "        #### Define the EMbddding Layer #### \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dims)\n",
    "\n",
    "        ## Define the LSTM Layer ## \n",
    "        self.lstm= nn.LSTM(input_size= self.embedding_dims, \n",
    "                              hidden_size= self.no_hidden, \n",
    "                               num_layers= self.no_layers, \n",
    "                               batch_first=True,\n",
    "                               dropout= 0.2)\n",
    "\n",
    "        ## Final classifier layers ## \n",
    "        self.dropout= nn.Dropout(0.2)\n",
    "        self.dense= nn.Linear(in_features= self.no_hidden, \n",
    "                             out_features= self.classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        ### INITIALIZE HIDDEN AND CELL STATE AS 0 ###\n",
    "        # h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)  # Num Layers x Batch Size x Hidden State\n",
    "        # c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)  # Num Layers x Batch Size x Hidden State\n",
    "        \n",
    "        x = self.embedding(x) # batch_size, seq_len, embed_dims \n",
    "        \n",
    "        op, (hn, cn) = self.lstm(x) # pass through LSTM (without zero h0, c0 intitalization)\n",
    "        last_hidden= op[ : ,-1 ,: ] #Extract the last hidden cell of each batch\n",
    "        \n",
    "        out= self.dropout(last_hidden)\n",
    "        out = self.dense(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "293118f1-5630-4439-bef8-d6635b096142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Device cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## SELECT DEVICE ##\n",
    "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on Device {device}\")\n",
    "\n",
    "## Load the model ## \n",
    "model= MyLSTM(vocab_size= len(vocabulary), \n",
    "                embedding_dims=128,\n",
    "                no_layers=1,\n",
    "                no_classes=2, \n",
    "                no_hidden= 256, \n",
    "                device= device)\n",
    "\n",
    "model= model.to(device)\n",
    "\n",
    "## Model Training Args ## \n",
    "epochs = 15\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.0005)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "batch_size = 128\n",
    "\n",
    "#### Build Training and Testing Dataset ####\n",
    "train_dataset = MyDataset(os.path.join(\"..\",\"data\",\"aclImdb\",\"train\"), vocabulary)\n",
    "test_dataset = MyDataset(os.path.join(\"..\",\"data\",\"aclImdb\",\"test\"), vocabulary)\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=data_collator)\n",
    "valloader = DataLoader(test_dataset, batch_size=128, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "def train(model, device, epochs, optimizer, loss_fn, batch_size, trainloader, valloader):\n",
    "    log_training = {\"epoch\": [],\n",
    "                    \"training_loss\": [],\n",
    "                    \"training_acc\": [],\n",
    "                    \"validation_loss\": [],\n",
    "                    \"validation_acc\": []}\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Starting Epoch {epoch}\")\n",
    "        training_losses, training_accuracies = [], []\n",
    "        validation_losses, validation_accuracies = [], []\n",
    "         \n",
    "        model.train() # Turn On BatchNorm and Dropout\n",
    "\n",
    "        for sent_, label in tqdm(trainloader):\n",
    "            sent_, label = sent_.to(device), label.to(device)\n",
    "            output= model(sent_)\n",
    "            # print(output.shape, label.shape)\n",
    "\n",
    "            ## calculate loss \n",
    "            loss= loss_fn(output, label)\n",
    "            training_losses.append(loss.item())\n",
    "\n",
    "            ## update the parameters \n",
    "            optimizer.zero_grad() \n",
    "            loss.backward() \n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 5) # Just in case ot exploding gradient problem \n",
    "            optimizer.step() \n",
    "\n",
    "            ## Calculate the training accuracy\n",
    "            predictions = torch.argmax(output, axis=1) \n",
    "            correct_labels = (predictions == label).sum() / len(predictions)  # avg accu. \n",
    "            training_accuracies.append(correct_labels.item())\n",
    "\n",
    "        model.eval() #turning off the gradients\n",
    "        for sent_, label in tqdm(valloader):\n",
    "            sent_, label = sent_.to(device), label.to(device)\n",
    "            with torch.no_grad():\n",
    "                output= model(sent_) \n",
    "\n",
    "                ## calculate loss \n",
    "                loss= loss_fn(output, label)\n",
    "                validation_losses.append(loss.item())\n",
    "    \n",
    "                ## Calculate the training accuracy\n",
    "                predictions = torch.argmax(output, axis=1) \n",
    "                correct_labels = (predictions == label).sum() / len(predictions)  # avg accu. \n",
    "                validation_accuracies.append(correct_labels.item())\n",
    "                \n",
    "        ## per epoch\n",
    "        training_loss_mean, training_acc_mean = np.mean(training_losses), np.mean(training_accuracies)\n",
    "        valid_loss_mean, valid_acc_mean = np.mean(validation_losses), np.mean(validation_accuracies)\n",
    "    \n",
    "        log_training[\"epoch\"].append(epoch)\n",
    "        log_training[\"training_loss\"].append(training_loss_mean)\n",
    "        log_training[\"training_acc\"].append(training_acc_mean)\n",
    "        log_training[\"validation_loss\"].append(valid_loss_mean)\n",
    "        log_training[\"validation_acc\"].append(valid_acc_mean)\n",
    "\n",
    "        print(\"Training Loss:\", training_loss_mean) \n",
    "        print(\"Training Acc:\", training_acc_mean)\n",
    "        print(\"Validation Loss:\", valid_loss_mean)\n",
    "        print(\"Validation Acc:\", valid_acc_mean)\n",
    "        \n",
    "        return log_training, model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "95e10d28-c839-4434-b404-ffdb3e0371bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 177/177 [16:39<00:00,  5.65s/it]\n",
      "100%|| 196/196 [04:23<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6897203797674448\n",
      "Training Acc: 0.5432314448437449\n",
      "Validation Loss: 0.7060917144527241\n",
      "Validation Acc: 0.5073740433673469\n",
      "CPU times: total: 48min 46s\n",
      "Wall time: 21min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training_logging, model = train(model=model,\n",
    "                                device=device,\n",
    "                                epochs=epochs,\n",
    "                                optimizer=optimizer,\n",
    "                                loss_fn=loss_fn,\n",
    "                                batch_size=batch_size,\n",
    "                                trainloader=trainloader,\n",
    "                                valloader=valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "52efbd2b-6323-42d3-9f26-373857374376",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9201d6-818b-41aa-91aa-632e38ecc056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
