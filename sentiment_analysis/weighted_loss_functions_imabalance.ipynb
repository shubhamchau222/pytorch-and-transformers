{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "799bcd37-f46b-45ed-a3f8-ebf294a402c3",
   "metadata": {},
   "source": [
    "# Use weighted loss function to solve imbalanced data classification problems\n",
    "\n",
    "Imbalanced datasets are a common problem in classification tasks, where number of instances in one class is significantly smaller than number of instances in another class. This will lead to biased models that perform poorly on minority class.\n",
    "\n",
    "    - Weighted loss function is a modification of standard loss function used in training a model.\n",
    "    - The weights are used to assign a higher penalty to mis classifications of minority class.\n",
    "    - The idea is to make model more sensitive to minority class by increasing cost of mis classification of that class.\n",
    "    - The most common way to implement a weighted loss function is to **assign higher weight to minority class** and lower weight to majority class\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40a98b8-ffd9-4d93-b75f-5a3450cc0f8c",
   "metadata": {},
   "source": [
    "## How to add weights to pytorchâ€™s common loss functions\n",
    "\n",
    "#### **Binary Classification (torch.nn.BCEWithLogitsLoss)**\n",
    "\n",
    "    **torch.nn.BCEWithLogitsLoss** function is a commonly used loss function for binary classification problems, where model output is a probability value between 0 and 1. It combines a sigmoid activation function with a binary cross-entropy loss.\n",
    "    - absFor imbalanced datasets, where number of instances in one class is significantly smaller than other, torch.nn.BCEWithLogitsLoss function can be modified by adding a weight parameter to loss function. The weight parameter allows to assign different weights for the positive and negative classes.\n",
    "\n",
    "**The weight parameter is a tensor of size [batch_size] that contains weight value for each sample in the batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47993519-3a07-49ee-a01e-6709552dd985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts: tensor([1000,  600], dtype=torch.int32)\n",
      "class weights : tensor([0.3750, 0.6250])\n",
      "\n",
      "Sample weights: tensor([[0.3750],\n",
      "        [0.6250],\n",
      "        [0.6250]])\n",
      "Inputs vector : tensor([[0.2851],\n",
      "        [0.6095],\n",
      "        [0.1164]]), torch.Size([3, 1]), ndim : 2\n",
      "Target vector : tensor([[0.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "Loss : 0.3287941515445709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the BCEWithLogitsLoss function with weight parameter\n",
    "class_counts = torch.tensor([1000,600], dtype=torch.int)\n",
    "print(f\"class counts: {class_counts}\")\n",
    "\n",
    "# class weights\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights/ class_weights.sum() #Higher weights to low count classes\n",
    "print(f\"class weights : {class_weights}\", end=\"\\n\\n\")\n",
    "\n",
    "# Assign correct weights per target class\n",
    "sample_weights = class_weights[target.view(-1).long()]  # Match target indices\n",
    "sample_weights = sample_weights.view(-1, 1)  # Reshape to match (N, 1)\n",
    "print(f\"Sample weights: {sample_weights}\")\n",
    "\n",
    "# Generate some random data for the binary classification problem\n",
    "input_ = torch.randn(3, 1)\n",
    "target = torch.tensor([[0.], [1.], [1.]])\n",
    "print(f\"Inputs vector : {input_}, {input_.shape}, ndim : {input_.ndim}\")\n",
    "print(f\"Target vector : {target}\")\n",
    "\n",
    "# loss function\n",
    "criterion = nn.BCEWithLogitsLoss(weight=sample_weights)\n",
    "loss = criterion(input_, target)\n",
    "print(f\"Loss : {loss}\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2afdc8-feed-4971-95ba-0637f8563dc3",
   "metadata": {},
   "source": [
    "#### weight_for_class_i = total_samples / (num_samples_in_class_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da5524f8-129b-41eb-83c1-d28abe239132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_for_class_0 : 1.6\n",
      "weight_for_class_1 : 2.6666666666666665\n"
     ]
    }
   ],
   "source": [
    "# Another ways\n",
    "weight_for_class_0 = 1600 / (1000)\n",
    "weight_for_class_1 = 1600 / (600)\n",
    "\n",
    "print(f\"weight_for_class_0 : {weight_for_class_0}\")\n",
    "print(f\"weight_for_class_1 : {weight_for_class_1}\") #assigning the higher weights to weaker classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe53b4e-8386-4191-86fb-1174aaf92749",
   "metadata": {},
   "source": [
    "```In addition to weight parameter, torch.nn.BCEWithLogitsLoss also has a pos_weight parameter, which is a simpler way to specify weight for positive class in a binary classification problem.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e049f017-9bb2-47c3-b871-b4af2f4a3590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7315)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the BCEWithLogitsLoss function with pos_weight parameter\n",
    "pos_weight = torch.tensor([3.0])  # higher weight for positive class\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# Generate some random data for the binary classification problem\n",
    "input = torch.randn(3, 1)\n",
    "target = torch.tensor([[0.], [1.], [1.]])\n",
    "\n",
    "# Compute the loss with the specified pos_weight\n",
    "loss = criterion(input, target)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c489b8cc-2375-4091-b237-7bbfb80cc85d",
   "metadata": {},
   "source": [
    "# Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cadee7-0b81-492c-aebd-4329fc4cae9c",
   "metadata": {},
   "source": [
    "## Suppose we have a dataset with 1000 samples, and target variable has three classes: Class A, Class B, and Class C. The distribution of samples in dataset is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f4f1729-d2d6-42b5-a702-cf31ee7b88b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts : tensor([100, 800, 100])\n",
      "Initial class weights : tensor([0.0100, 0.0012, 0.0100])\n",
      "Normalized class weights : tensor([0.4706, 0.0588, 0.4706])\n",
      "Normalized class weights in percentages : tensor([47.0588,  5.8824, 47.0588])\n"
     ]
    }
   ],
   "source": [
    "# class a: 100 samples\n",
    "# class b: 800 samples\n",
    "# class c: 100 samples\n",
    "\n",
    "counts = [100,800,100]\n",
    "class_counts= torch.tensor(counts)\n",
    "print(f\"class counts : {class_counts}\")\n",
    "\n",
    "#class weights \n",
    "class_weights = 1.0 / class_counts\n",
    "print(f\"Initial class weights : {class_weights}\")\n",
    "\n",
    "# normalized classweights \n",
    "class_weights= class_weights/class_weights.sum()\n",
    "print(f\"Normalized class weights : {class_weights}\")\n",
    "print(f\"Normalized class weights in percentages : {class_weights*100}\")\n",
    "\n",
    "#loss functions \n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8188dc0c-4bf3-4681-8adc-7dbee88faff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c3f31c40-e1a6-4044-b207-06bbbaff35dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated class weights : tensor([10.0000,  1.2500, 10.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([10.0000,  1.2500, 10.0000])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another ways\n",
    "\n",
    "counts = [100,800,100]\n",
    "count_sum= sum(counts)\n",
    "class_weightsUpdated= [sum(counts)/x for x in counts]\n",
    "\n",
    "class_weightsUpdated = torch.tensor(class_weightsUpdated)\n",
    "print(\"Updated class weights :\",class_weightsUpdated)\n",
    "\n",
    "## Loss function\n",
    "\n",
    "loss_fn= torch.nn.CrossEntropyLoss(weight=class_weightsUpdated)\n",
    "loss_fn.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef98bb-befa-4b16-8650-de0b71ffbf22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed9b89-226d-4c96-9a4e-fe7c9947846e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb85da-6841-4d9a-8d7b-449d10331fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b47d49d-3281-4ccf-8910-8482c9686d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
